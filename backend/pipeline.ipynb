{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLLB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mekae\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "# Load model and tokenizer\n",
    "model_name = \"facebook/nllb-200-distilled-600M\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(source_text, source_lang, target_lang):\n",
    "\n",
    "    # Kinyarwanda Tokenizer\n",
    "    tokenizer.src_lang = source_lang\n",
    "\n",
    "    # Tokenize the input text\n",
    "    inputs = tokenizer(source_text, return_tensors=\"pt\")\n",
    "\n",
    "    # Generate the translation according to target language specified\n",
    "    translated_tokens = model.generate(\n",
    "        **inputs, forced_bos_token_id=tokenizer.lang_code_to_id[target_lang], max_length=30\n",
    "    )\n",
    "\n",
    "    # Decode the translated tokens for translated text\n",
    "    translated_text = tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n",
    "\n",
    "    return translated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "the `lang_code_to_id` attribute is deprecated. The logic is natively handled in the `tokenizer.adder_tokens_decoder` this attribute will be removed in `transformers` v4.38\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'不过,我没有到这里来,要小心.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"Didn't get here being careful\", \"en\", \"zho_Hans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'斯坦福大学医学院的学生周一宣布发明了一种新的诊断工具,可以根据小型印花芯片的'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate(\"Students from Stanford University Medical School announced Monday the invention of a new diagnostic tool that can sort cells by type of small printed chip\",  \"en\", \"zho_Hans\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MQM Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd6108808e09486c82f38eb4349952c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 6 files:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mekae\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Encoder model frozen.\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "# pip install unbabel-comet is the one for the below line, otherwise it's pip install comet or pip install comet-ml I don't know\n",
    "from comet import download_model, load_from_checkpoint\n",
    "# Download the model\n",
    "token = \"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\"\n",
    "mqm_model_path = snapshot_download(repo_id=\"Unbabel/wmt23-cometkiwi-da-xl\", use_auth_token=token)\n",
    "\n",
    "\n",
    "\n",
    "# Load the model from the checkpoint\n",
    "mqm_model = load_from_checkpoint(mqm_model_path + '\\checkpoints\\model.ckpt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:01<00:00,  1.21s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction([('scores', [0.15611198544502258]),\n",
       "            ('system_score', 0.15611198544502258)])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [{\n",
    "    \"src\": \"Didn't get here being careful\",\n",
    "    \"mt\":  \"不过,我没有到这里来,要小心.\",\n",
    "    }]\n",
    "\n",
    "mqm_model.predict(data, batch_size=1, gpus=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-Grained Error Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [{\n",
    "    \"src\": \"Didn't get here being careful\",\n",
    "    \"mt\":  \"不过,我没有到这里来,要小心.\",\n",
    "    }]\n",
    "\n",
    "mqm_model.predict(data, batch_size=1, gpus=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from comet import download_model, load_from_checkpoint\n",
    "# This line comes with quite the issues, we don't know the full solution yet but do \n",
    "# pip install \"unbabel-comet>=2.2.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d396240594b347749f5e99467b13e4e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Encoder model frozen.\n",
      "C:\\Users\\mekae\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pytorch_lightning\\core\\saving.py:177: Found keys that are not in the model state dict but in the checkpoint: ['encoder.model.embeddings.position_ids']\n"
     ]
    }
   ],
   "source": [
    "from comet import download_model, load_from_checkpoint\n",
    "\n",
    "FGED_model_path = download_model(\"Unbabel/XCOMET-XL\")\n",
    "FGED_model = load_from_checkpoint(FGED_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import json\n",
    "\n",
    "# Set the precision to 'medium' for a balance between performance and precision\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Set up OpenAI Client\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key= OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:00<00:00,  1.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction([('scores', [0.4809541404247284]), ('system_score', 0.4809541404247284), ('metadata', Prediction([('src_scores', [0.33455660939216614]), ('mqm_scores', [1.0]), ('error_spans', [[]])]))])\n",
      "[0.4809541404247284]\n",
      "0.4809541404247284\n",
      "[[]]\n"
     ]
    }
   ],
   "source": [
    "data = [{\n",
    "    \"src\": \"Talking about risks, I take those. Didn't get here being careful\",\n",
    "    # \"mt\":  \"談到風險，我承擔這些風險。沒到這裡小心點\",\n",
    "    \"mt\":  \"谈到风险,我会承担这些风险.我没有来这里是谨慎的.\",\n",
    "\n",
    "    # \"src\": \"Students from Stanford University Medical School announced Monday the invention of a new diagnostic tool that can sort cells by type of small printed chip\",\n",
    "    # \"mt\":  \"史丹佛大學醫學院的學生週一宣布發明了一種新的診斷工具，可以根據小型印刷晶片的類型對細胞進行分類\",\n",
    "    \n",
    "    # \"src\": \"23 should be all on my back\",\n",
    "    # \"mt\":  \"23岁应该是我背后的.\",\n",
    "    \n",
    "    \n",
    "    # \"src\": \"Well rounded searching for the right outlet\",\n",
    "    # \"mt\":  \"即使一个男人倒下,我也会变得更强大. 圆满寻找合适的输出口.\",\n",
    "\n",
    "    # \"src\": \"The government is investing in infrastructure projects to boost the economy and create jobs\",\n",
    "    # \"mt\":  \"政府正在投資基礎設施項目，以促進經濟增長並創造就業機會\",\n",
    "    }]\n",
    "\n",
    "\n",
    "FGED_model.eval()\n",
    "with torch.no_grad(): \n",
    "    FGED_model_output = FGED_model.predict(data, batch_size=1, gpus=1)\n",
    "\n",
    "print(FGED_model_output)\n",
    "\n",
    "# Segment-level scores\n",
    "print (FGED_model_output.scores)\n",
    "\n",
    "# System-level score\n",
    "print (FGED_model_output.system_score)\n",
    "\n",
    "# Score explanation (error spans)\n",
    "print (FGED_model_output.metadata.error_spans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"errors\": [\n",
      "        {\n",
      "            \"original_text\": \"\\u8c28\\u614e\\u7684.\",\n",
      "            \"translated_text\": \"careful.\",\n",
      "            \"correct_text\": \"careful\",\n",
      "            \"start_index_orig\": 1,\n",
      "            \"end_index_orig\": 5,\n",
      "            \"start_index_translation\": 6,\n",
      "            \"end_index_translation\": 13,\n",
      "            \"error_type\": \"Mask In-filling\"\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo-16k\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"text\": \"You are an expert in multilingual translations. Given MQM scores, corrected text, error spans, you will determine a classification for the error out of ONLY one of the following: Addition of Text ,Negation Errors ,Mask In-filling ,Named Entity (NE) Errors ,Number (NUM) Errors ,Hallucinations\\n\\nThen turn that into this format by correctly indicating the start and end corresponding indices\\n\\n{\\r\\n    \\\"errors\\\": [\\r\\n      {\\r\\n        \\\"original_text\\\": \\\"Учените\\\",\\r\\n        \\\"translated_text\\\": \\\"Students\\\",\\r\\n        \\\"correct_text\\\": \\\"Scientists\\\",\\r\\n        \\\"start_index_orig\\\": 0,\\n\\r\\n        \\\"end_index_orig\\\": 7,\\r\\n        \\\"start_index_translation\\\": 0,\\r\\n        \\\"end_index_translation\\\": 7,\\r\\n        \\\"error_type\\\": \\\"Incorrect Subject\\\"\\r\\n      } \\n    ]\\r\\n  }\\r\\n\\r\\n\",\n",
    "          \"type\": \"text\"\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": str(data[0]) + \"\\n\\n\" + str(FGED_model_output.system_score) + \" \" + str(FGED_model_output.metadata.error_spans)\n",
    "        }\n",
    "      ]\n",
    "    },\n",
    "  ],\n",
    "  temperature=1,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "\n",
    "json_object = json.loads(response.choices[0].message.content)\n",
    "print(json.dumps(json_object, indent=4))\n",
    "\n",
    "\n",
    "with open('response.json', 'w') as f:\n",
    "    json.dump(json_object, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<span>Cause the<span class='highlight' id='highlight-0' style='background-color: #800080; padding: 0vh 0vw 0vh 0vw; zIndex: 0'>y do</span>n't want to see you win dawg</span>\n"
     ]
    }
   ],
   "source": [
    "color_mappings = {\n",
    "    \"Addition of Text\": \"#FF5733\",\n",
    "    \"Negation Errors\": \"#00A0F0\",\n",
    "    \"Mask In-filling\": \"#59c00a\",\n",
    "    \"Named Entity (NE) Errors\": \"#D3365A\",\n",
    "    \"Number (NUM) Errors\": \"#8B4513\",\n",
    "    \"Hallucinations\": \"#800080\",\n",
    "    \"No Error\": \"#2f3472\"\n",
    "}\n",
    "\n",
    "# final = translation\n",
    "final = \"Cause they don't want to see you win dawg\"\n",
    "\n",
    "zIndex = 0\n",
    "offset = 0\n",
    "\n",
    "for error in spans[\"errors\"]:\n",
    "    # init\n",
    "    start = error[\"start_index_translation\"]\n",
    "    end = error[\"end_index_translation\"]\n",
    "    if error[\"error_type\"] in color_mappings: \n",
    "        color = color_mappings[error[\"error_type\"]]\n",
    "    else:\n",
    "        color = \"#FFFFFF\"\n",
    "\n",
    "    id = zIndex\n",
    "\n",
    "    # tags\n",
    "    Ltag = \"<span class='highlight' id='highlight-\" + str(id) + \"' style='background-color: \" + color + \"; padding: \" + str(zIndex) + \"vh 0vw \" + str(zIndex) + \"vh 0vw; zIndex: \" + str(zIndex) + \"'>\"\n",
    "    Rtag = \"</span>\"\n",
    "    \n",
    "    # Algo\n",
    "    # Must go left to right if we use this ordering of offset\n",
    "    final = final[:start + offset] + Ltag + final[start + offset:end + offset] + Rtag + final[end + offset:]\n",
    "    offset += len(Ltag) + len(Rtag)\n",
    "    zIndex += 1\n",
    "\n",
    "print(\"<span>\" + final + \"</span>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.3056.0_x64__qbz5n2kfra8p0\\lib\\site-packages\\pkg_resources\\__init__.py:123: PkgResourcesDeprecationWarning: otobuf is an invalid version and will not be supported in a future release\n",
      "  warnings.warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [00:02<00:00,  2.20s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Prediction([('scores', [0.8951457142829895]),\n",
       "            ('system_score', 0.8951457142829895),\n",
       "            ('metadata',\n",
       "             Prediction([('src_scores', [0.921981692314148]),\n",
       "                         ('mqm_scores', [0.800000011920929]),\n",
       "                         ('error_spans',\n",
       "                          [[{'text': '赢得比赛',\n",
       "                             'confidence': 0.41127336025238037,\n",
       "                             'severity': 'major',\n",
       "                             'start': 9,\n",
       "                             'end': 13}]])]))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Example data\n",
    "data = [\n",
    "    {\n",
    "        # \"src\": \"Students from Stanford University Medical School announced Monday the invention of a new diagnostic tool that can sort cells by type of small printed chip\",\n",
    "        # \"mt\":  \"史丹佛大學醫學院的學生週一宣布發明了一種新的診斷工具，可以根據小型印刷晶片的類型對細胞進行分類\",\n",
    "        \n",
    "        \"src\": \"Cause they don't want to see you win dawg\",\n",
    "        \"mt\":  \"因为他们不想看到你赢得比赛.\",\n",
    "    },\n",
    "    # Add more data pairs as needed\n",
    "]\n",
    "\n",
    "# Run prediction\n",
    "predictions = FGED_model.predict(data, batch_size=8, gpus=1)\n",
    "predictions\n",
    "# # Process and print detailed output\n",
    "# for prediction in predictions:\n",
    "#     print(\"Quality Score:\", prediction['score'])\n",
    "#     for error in prediction['error_spans']:\n",
    "#         print(f\"Text: {error['text']}, Confidence: {error['confidence']}, Severity: {error['severity']}, Type: {error['type']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Prediction([('scores', [0.9770506620407104]),\n",
       "            ('system_score', 0.9770506620407104),\n",
       "            ('metadata',\n",
       "             Prediction([('src_scores', [0.9818598628044128]),\n",
       "                         ('mqm_scores', [0.9599999785423279]),\n",
       "                         ('error_spans',\n",
       "                          [[{'text': '小型印刷晶片',\n",
       "                             'confidence': 0.3709107041358948,\n",
       "                             'severity': 'minor',\n",
       "                             'start': 31,\n",
       "                             'end': 37}]])]))])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for prediction in predictions:\n",
    "    # print(prediction)\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_span_mappings = {\n",
    "    \"lexical_errors\": {\n",
    "        \"Addition of Text\": \"Extra content added that was not present in the source text.\",\n",
    "        \"Negation Errors\": \"Incorrect handling of negations, changing the meaning of the sentence.\",\n",
    "        \"Mask In-filling\": \"Issues where masked parts are filled incorrectly.\",\n",
    "        \"Named Entity (NE) Errors\": \"Incorrect translation or handling of named entities like names, places, etc.\",\n",
    "        \"Number (NUM) Errors\": \"Errors related to numbers, such as incorrect translation of quantities.\",\n",
    "        \"Hallucinations\": \"Pathological translations where content is detached from the source.\"\n",
    "    },\n",
    "    \"error_severity\": {\n",
    "        \"OK\": \"Correct translation with no issues.\",\n",
    "        \"MIN\": \"Small errors that might affect fluency or slightly alter the meaning.\",\n",
    "        \"MAJ\": \"Significant errors that affect the meaning or readability of the translation.\",\n",
    "        \"CRIT\": \"Severe errors that render the translation incorrect or highly misleading.\"\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'errors': [{'original_text': 'Учените',\n",
       "   'translated_text': 'Students',\n",
       "   'correct_text': 'Scientists',\n",
       "   'start_index_orig': 0,\n",
       "   'end_index_orig': 7,\n",
       "   'start_index_translation': 0,\n",
       "   'end_index_translation': 7,\n",
       "   'error_type': 'Incorrect Subject'},\n",
       "  {'original_text': 'който може да сортира клетките по тип: малък печатен чип',\n",
       "   'translated_text': '',\n",
       "   'correct_text': 'that can sort cells by type: small printed chip',\n",
       "   'start_index_orig': 75,\n",
       "   'end_index_orig': 131,\n",
       "   'start_index_translation': 86,\n",
       "   'end_index_translation': 108,\n",
       "   'error_type': 'Omission'},\n",
       "  {'original_text': 'изобретяването на нов диагностичен инструмент',\n",
       "   'translated_text': 'the invention of a new diagnostic tool that can sort cells by a type of small printed',\n",
       "   'correct_text': 'the invention of a new diagnostic tool',\n",
       "   'start_index_orig': 43,\n",
       "   'end_index_orig': 75,\n",
       "   'start_index_translation': 51,\n",
       "   'end_index_translation': 108,\n",
       "   'error_type': 'Incomplete Sentence'}]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('sample_error_span.json', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Error Span Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highlighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation = \"Students from Stanford University Medical School announced Monday the invention of a new diagnostic tool that can sort cells by type of small printed chip\"\n",
    "\n",
    "spans = [\n",
    "{\n",
    "    \"errors\": [\n",
    "    {\n",
    "        \"original_text\": \"Учените\",\n",
    "        \"translated_text\": \"Students\",\n",
    "        \"correct_text\": \"Scientists\",\n",
    "        \"start_index_orig\": 0,\n",
    "        \"end_index_orig\": 7,\n",
    "        \"start_index_translation\": 0,\n",
    "        \"end_index_translation\": 7,\n",
    "        \"error_type\": \"Incorrect Subject\"\n",
    "    },\n",
    "    {\n",
    "        \"original_text\": \"изобретяването на нов диагностичен инструмент\",\n",
    "        \"translated_text\": \"the invention of a new diagnostic tool that can sort cells by a type of small printed\",\n",
    "        \"correct_text\": \"the invention of a new diagnostic tool\",\n",
    "        \"start_index_orig\": 43,\n",
    "        \"end_index_orig\": 75,\n",
    "        \"start_index_translation\": 51,\n",
    "        \"end_index_translation\": 108,\n",
    "        \"error_type\": \"Incomplete Sentence\"\n",
    "    },\n",
    "    # {\n",
    "    #     \"original_text\": \"който може да сортира клетките по тип: малък печатен чип\",\n",
    "    #     \"translated_text\": \"\",\n",
    "    #     \"correct_text\": \"that can sort cells by type: small printed chip\",\n",
    "    #     \"start_index_orig\": 75,\n",
    "    #     \"end_index_orig\": 131,\n",
    "    #     \"start_index_translation\": 52,\n",
    "    #     \"end_index_translation\": 106,\n",
    "    #     \"error_type\": \"Omission\"\n",
    "    # },\n",
    "    {\n",
    "        \"original_text\": \"който може да сортира клетките по тип: малък печатен чип\",\n",
    "        \"translated_text\": \"\",\n",
    "        \"correct_text\": \"that can sort cells by type: small printed chip\",\n",
    "        \"start_index_orig\": 75,\n",
    "        \"end_index_orig\": 131,\n",
    "        \"start_index_translation\": 86,\n",
    "        \"end_index_translation\": 108,\n",
    "        \"error_type\": \"Omission\"\n",
    "    }\n",
    "    ]\n",
    "}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "spans = [{\n",
    "    \"errors\": [\n",
    "        {\n",
    "            \"original_text\": \"\\u8ac7\\u5230\\u98a8\\u96aa\\uff0c\\u6211\\u627f\\u64d4\\u9019\\u4e9b\\u98a8\\u96aa\\u3002\",\n",
    "            \"translated_text\": \"Talking about risks, I take those.\",\n",
    "            \"correct_text\": \"Talking about risks, I take these risks.\",\n",
    "            \"start_index_orig\": 0,\n",
    "            \"end_index_orig\": 20,\n",
    "            \"start_index_translation\": 0,\n",
    "            \"end_index_translation\": 20,\n",
    "            \"error_type\": \"Addition of Text\"\n",
    "        }\n",
    "    ]\n",
    "}]\n",
    "\n",
    "\n",
    "spans = {\n",
    "    'errors': [\n",
    "        {\n",
    "            'original_text': '赢得比赛', \n",
    "            'translated_text': 'win the game', \n",
    "            'correct_text': 'win the game',\n",
    "            'start_index_orig': 9,\n",
    "            'end_index_orig': 13,\n",
    "            'start_index_translation': 9,\n",
    "            'end_index_translation': 13,\n",
    "            'error_type': 'Hallucinations'\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "translation = translate(\"Students from Stanford University Medical School announced Monday the invention of a new diagnostic tool that can sort cells by type of small printed chip\",  \"en\", \"zho_Hans\")\n",
    "spans = json_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'original_text': '小型印刷晶片', 'translated_text': 'small printed chip', 'correct_text': 'small printed chip', 'start_index_orig': 31, 'end_index_orig': 37, 'start_index_translation': 31, 'end_index_translation': 37, 'error_type': 'No Error'}]\n"
     ]
    }
   ],
   "source": [
    "spans\n",
    "\n",
    "for error in spans:\n",
    "    print(spans[error]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\mekae\\\\.cache\\\\huggingface\\\\hub\\\\models--Unbabel--XCOMET-XL\\\\snapshots\\\\baa17625e541fe87c4c0010616e35eab12c864f7\\\\checkpoints\\\\model.ckpt'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FGED_model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'translation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtranslation\u001b[49m[\u001b[38;5;241m2\u001b[39m:\u001b[38;5;241m7\u001b[39m]\n\u001b[0;32m      3\u001b[0m t \u001b[38;5;241m=\u001b[39m translation[:\u001b[38;5;241m4\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAHHHH\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m translation[\u001b[38;5;241m4\u001b[39m:]\n\u001b[0;32m      4\u001b[0m t\n",
      "\u001b[1;31mNameError\u001b[0m: name 'translation' is not defined"
     ]
    }
   ],
   "source": [
    "translation[2:7]\n",
    "\n",
    "t = translation[:4] + \"AHHHH\" + translation[4:]\n",
    "t\n",
    "offset = len(\"AHHHH\")\n",
    "translation[2:7]\n",
    "t[2 + offset : 7 + offset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 36\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<span>\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m final \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m</span>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m colors \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAddition of Text\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#FF5733\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNegation Errors\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#00A0F0\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo Error\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#FFFFFF\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     34\u001b[0m }\n\u001b[1;32m---> 36\u001b[0m \u001b[43merrorSpanHighlighter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtranslation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# spans\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m, in \u001b[0;36merrorSpanHighlighter\u001b[1;34m(translation, spans, color_mappings)\u001b[0m\n\u001b[0;32m      4\u001b[0m zIndex \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      5\u001b[0m offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m error \u001b[38;5;129;01min\u001b[39;00m \u001b[43mspans\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43merrors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# init\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     start \u001b[38;5;241m=\u001b[39m error[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_index_translation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     10\u001b[0m     end \u001b[38;5;241m=\u001b[39m error[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_index_translation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "def errorSpanHighlighter(translation, spans, color_mappings):\n",
    "    final = translation\n",
    "\n",
    "    zIndex = 0\n",
    "    offset = 0\n",
    "\n",
    "    for error in spans[\"errors\"]:\n",
    "        # init\n",
    "        start = error[\"start_index_translation\"]\n",
    "        end = error[\"end_index_translation\"]\n",
    "        color = color_mappings[error[\"error_type\"]]\n",
    "\n",
    "        # tags\n",
    "        Ltag = \"<span class='highlight' style='background-color: \" + color + \"; padding: \" + str(zIndex) + \"vh 0vw \" + str(zIndex) + \"vh 0vw; zIndex: \" + str(zIndex) + \"'>\"\n",
    "        Rtag = \"</span>\"\n",
    "        \n",
    "        # Algo\n",
    "        # Must go left to right if we use this ordering of offset\n",
    "        final = final[:start + offset] + Ltag + final[start + offset:end + offset] + Rtag + final[end + offset:]\n",
    "        offset += len(Ltag) + len(Rtag)\n",
    "        zIndex += 1\n",
    "\n",
    "    return \"<span>\" + final + \"</span>\"\n",
    "\n",
    "\n",
    "colors = {\n",
    "    \"Addition of Text\": \"#FF5733\",\n",
    "    \"Negation Errors\": \"#00A0F0\",\n",
    "    \"Mask In-filling\": \"#59c00a\",\n",
    "    \"Named Entity (NE) Errors\": \"#D3365A\",\n",
    "    \"Number (NUM) Errors\": \"#8B4513\",\n",
    "    \"Hallucinations\": \"#800080\",\n",
    "    \"No Error\": \"#FFFFFF\"\n",
    "}\n",
    "\n",
    "errorSpanHighlighter(translation, spans, colors)\n",
    "\n",
    "# spans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 33\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<span>\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m final \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m</span>\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     27\u001b[0m colors \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect Subject\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#00A0F0\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOmission\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#59c00aba\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     30\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncomplete Sentence\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m#D3365A\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     31\u001b[0m }\n\u001b[1;32m---> 33\u001b[0m \u001b[43merrorSpanHighlighter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtranslation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolors\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[68], line 7\u001b[0m, in \u001b[0;36merrorSpanHighlighter\u001b[1;34m(translation, spans, color_mappings)\u001b[0m\n\u001b[0;32m      4\u001b[0m zIndex \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      5\u001b[0m offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m error \u001b[38;5;129;01min\u001b[39;00m \u001b[43mspans\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrors\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m# init\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     start \u001b[38;5;241m=\u001b[39m error[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_index_translation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     10\u001b[0m     end \u001b[38;5;241m=\u001b[39m error[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend_index_translation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "\n",
    "def errorSpanHighlighter(translation, spans, color_mappings):\n",
    "    final = translation\n",
    "\n",
    "    zIndex = 0\n",
    "    offset = 0\n",
    "\n",
    "    for error in spans[0][\"errors\"]:\n",
    "        # init\n",
    "        start = error[\"start_index_translation\"]\n",
    "        end = error[\"end_index_translation\"]\n",
    "        color = color_mappings[error[\"error_type\"]]\n",
    "\n",
    "        # tags\n",
    "        Ltag = \"<span class='highlight' style='background-color: \" + color + \"; padding: \" + str(zIndex) + \"vh 0vw \" + str(zIndex) + \"vh 0vw; zIndex: \" + str(zIndex) + \"'>\"\n",
    "        Rtag = \"</span>\"\n",
    "        \n",
    "        # Algo\n",
    "        # Must go left to right if we use this ordering of offset\n",
    "        final = final[:start + offset] + Ltag + final[start + offset:end + offset] + Rtag + final[end + offset:]\n",
    "        offset += len(Ltag) + len(Rtag)\n",
    "        zIndex += 1\n",
    "\n",
    "    return \"<span>\" + final + \"</span>\"\n",
    "\n",
    "\n",
    "\n",
    "colors = {\n",
    "    \"Incorrect Subject\": \"#00A0F0\",\n",
    "    \"Omission\": \"#59c00aba\",\n",
    "    \"Incomplete Sentence\": \"#D3365A\",\n",
    "}\n",
    "\n",
    "errorSpanHighlighter(translation, spans, colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI(api_key= OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feeding the model (OpenAI API) the original translation meta descriptors and prompting for a new/rephrased/alternate translation\n",
    "def rephrase(previous_translations, original_source_text, source_language, target_language):\n",
    "\n",
    "  # Construct the prompt for rephrased/alternate translation\n",
    "  prompt = f'''Please provide an alternative translation to and rephrase: \"{previous_translations}\"\n",
    "          The original text was {original_source_text}.\n",
    "          The source language is {source_language} and the target language is {target_language}.'''\n",
    "\n",
    "\n",
    "  response = client.chat.completions.create(\n",
    "    # model=\"gpt-4o-2024-05-13\",\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": f\"Please provide an alternative translation to and rephrase: \\\"{previous_translations}\\\"\\r\\n          The original text was {original_source_text}.\\r\\n          The source language is {source_language} and the target language is {target_language}. Give only the translation\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "    temperature=1,\n",
    "    max_tokens=256,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0\n",
    "  )\n",
    "\n",
    "  return response.choices[0].message.content\n",
    "\n",
    "# Get alternative translation for demo text\n",
    "previous_translations = [\n",
    "  \"The weather is great today, let's take a walk in the park together.\",\n",
    "  \"Today's weather is wonderful, shall we go for a walk in the park?\",\n",
    "  \"It's a beautiful day today, how about we go for a stroll in the park?\",\n",
    "]\n",
    "\n",
    "# Probably want to use the Translation memory/storage for avoiding repeat translations and get unique results each time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"The weather is very nice today, let's go for a walk in the park together.\"\n"
     ]
    }
   ],
   "source": [
    "original_source_text = \"今天的天气非常好，我们一起去公园散步吧。\"\n",
    "source_language = \"zh\"\n",
    "target_language = \"en\"\n",
    "\n",
    "\n",
    "alternative_translation = rephrase(previous_translations, original_source_text, source_language, target_language)\n",
    "previous_translations.append(alternative_translation)\n",
    "print(alternative_translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The weather is great today, let's take a walk in the park together.\n",
      "Today's weather is wonderful, shall we go for a walk in the park?\n",
      "It's a beautiful day today, how about we go for a stroll in the park?\n",
      "The weather is fantastic today, let's go for a walk in the park together.\n",
      "\"The weather is very nice today, let's go for a walk in the park together.\"\n"
     ]
    }
   ],
   "source": [
    "for x in previous_translations:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHINESE TO ENGLISH EXAMPLE\n",
      "Fiber optic cable, in the dark it fades away, lost in night's play. \n",
      "\n",
      "\n",
      "Why did the fiber optics turn black when the light hit them? \n",
      "\n",
      "\n",
      "ENGLISH TO CHINESE EXAMPLE\n",
      "时光荏苒，忘我迷离。 \n",
      "\n",
      "\n",
      "我完全搞不清时间，我烦死了。\n"
     ]
    }
   ],
   "source": [
    "# Few-shot context changing via user input\n",
    "def edit_context(context, original_text, source_language, target_language, few_shot_examples):\n",
    "\n",
    "  response = client.chat.completions.create(\n",
    "    # model=\"gpt-4o-2024-05-13\",\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=[\n",
    "    {\n",
    "      \"role\": \"system\",\n",
    "      \"content\": [\n",
    "        {\n",
    "          \"type\": \"text\",\n",
    "          \"text\": f'''Translate \"{original_text}\" from the {source_language} language, into the {target_language} language\n",
    "                      using the following context style: \"{context}\".\n",
    "                      Here are some examples of the style being used: {few_shot_examples}\n",
    "                      '''\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "  ],\n",
    "    temperature=1,\n",
    "    max_tokens=256,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0\n",
    "  )\n",
    "\n",
    "  return response.choices[0].message.content\n",
    "\n",
    "\n",
    "print(\"CHINESE TO ENGLISH EXAMPLE\")\n",
    "\n",
    "# Poetic Example\n",
    "examples = '''\"Light speeds away, in a blink it will fly.\"\n",
    "              \"Stars reach from afar, with light from eons bold.\"\n",
    "           '''\n",
    "\n",
    "print(edit_context(\"A poetic two line rhyming style\", \"光纤照上去变成黑光纤了\", \"zh\", \"en\", examples), \"\\n\\n\")\n",
    "\n",
    "# Confused and Inquisitive Example\n",
    "examples = '''\"How does it work so well when it's so unclear?\"\n",
    "              \"Why did it begin so suddenly, what triggered it?\"\n",
    "            '''\n",
    "\n",
    "print(edit_context(\"A confused and inquisitive style\", \"光纤照上去变成黑光纤了\", \"zh\", \"en\", examples), \"\\n\\n\")\n",
    "\n",
    "\n",
    "\n",
    "# English to Chinese Example\n",
    "print(\"ENGLISH TO CHINESE EXAMPLE\")\n",
    "\n",
    "# Poetic Example\n",
    "examples = '''\"光逝如飞，瞬息即逝。\"\n",
    "              \"星光遥来，古光犹豪。\"\n",
    "           '''\n",
    "\n",
    "print(edit_context(\"A poetic two line rhyming style\", \"Lose track of time I'm bugging\", \"en\", \"zh\", examples), \"\\n\\n\")\n",
    "\n",
    "# Confused and Inquisitive Example\n",
    "examples = '''\"当它如此不清楚时，它如何运作得这么好？\"\n",
    "              \"为什么它开始得这么突然，是什么触发了它？\"\n",
    "            '''\n",
    "\n",
    "print(edit_context(\"A confused and inquisitive style\", \"Lose track of time I'm bugging\", \"en\", \"zh\", examples))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
