{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Config\n",
    "\n",
    "\n",
    "Note from Mekael\n",
    "- For my team, use a virutal environment to keep deployment operations clean and tidy\n",
    "- You can do this by running the following command in your terminal\n",
    "- `python -m venv error-in-translations`\n",
    "- Activate the environment by selecting it as your kernel for your jupyter notebook. If it doesn't work you will have to figure it out\n",
    "- pip install the packages in the requirements file in the root directory of this repo\n",
    "- `pip install -r requirements.txt`\n",
    "\n",
    "\n",
    "- **If you install new packages that are not included in the environment, please add it to the requirements file manually or generate a new requirements file with the following command in the terminal**\n",
    "- `pip freeze > requirements.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/openlanguagedata/flores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\mekae\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.0.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\mekae\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "# !pip install sacrebleu\n",
    "# !pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import spacy\n",
    "import random\n",
    "import sacrebleu\n",
    "\n",
    "# Not working\n",
    "OPENAI_API_KEY = 'sk-proj-o9TONJi0MW2tSiDMhRkxT3BlbkFJkUr03XQ5IfUaxamV0e3k'\n",
    "\n",
    "# Mekael's Personal Key, not being shared\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Benchmark\n",
    "\n",
    "This benchmark sets a baseline and tests the translation precision & accuracy our POC pipeline, against the bare translation capabilities of OPENAI's CHATGPT 3.5 Turbo via their API.\n",
    "\n",
    "If our POC performs better than the stock GPT 3.5 Turbo, it means that our proposed method is valubale and worthwhile to implement. \n",
    "\n",
    "For baseline testing purposes, our POC makes use of custom GPT 3.5 API prompting as the translation model as well as the quality estimation model. These will be replaced with a more sophisticated custom LLM solution during actual implementation.\n",
    "\n",
    "We will be using Meta's Flores 200 dataset for this testing, and scores will be in the form of spBLEU and/or chrF++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_dataset = \"../flores/floresp-v2.0-rc.2/dev/dev.eng_Latn\"\n",
    "\n",
    "# Rename the Column\n",
    "column_names = [\"Text Lines\"]\n",
    "\n",
    "# Read in the Flores Dataset English Latn\n",
    "df = pd.read_csv(english_dataset, delimiter = '\\t', header=None, names=column_names)\n",
    "# df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translations using our proposed method (POC) and stock GPT 3.5 Turbo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add POC (no glossary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt with entity translation\n",
    "def prompt_generator(text, source_language, target_language):\n",
    "  # terms = identify_entities(text)\n",
    "  # terms_translations = '. '.join([f\"'{k}': '{v}'\" for k, v in terms.items()])\n",
    "  # translations = f\"Based on the translation of following term: {terms_translations}.\"\n",
    "  prompt = f\"Translate the following text from {source_language[8:]} into {target_language[8:]}: {text}\\n\"\n",
    "  # if terms == {}:\n",
    "    # return prompt\n",
    "  # prompt = translations + prompt\n",
    "  \n",
    "  prompt = prompt\n",
    "\n",
    "  return prompt\n",
    "\n",
    "# prompt = prompt_generator('光纤照上去变成黑光纤了', 'zh', 'en')\n",
    "# print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Translation code, can be replaced by other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(prompt):\n",
    "\n",
    "    client = OpenAI(api_key= OPENAI_API_KEY,)\n",
    "    print(prompt)\n",
    "    response = client.chat.completions.create(\n",
    "      messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "          }],\n",
    "      model=\"gpt-3.5-turbo\",)\n",
    "    translation = response.choices[0].message.content.strip().split(\"\\n\")[0]\n",
    "    return translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quality Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_estimator(original_text, translated_text):\n",
    "  client = OpenAI(api_key= OPENAI_API_KEY,)\n",
    "  prompt = f\"Evaluate the quality estimation of the following source and translation sentence pairs by following a step-by-step process: \\\n",
    "    Step 1: Estimate the perplexity of the translated sentence.\\\n",
    "    Step 2: Determine the token-level similarity between the source and translatedsentences.\\\n",
    "    Step 3: Combine the results and classify the translation quality into one of the following categories:'No meaning preserved', 'Some meaning preserved, but not understandable', 'Some meaning preserved and understandable', 'Most meaningpreserved, minor issues',or 'Perfect translation'.\\\n",
    "    Source:{original_text}.Translation:{translated_text}\"\n",
    "  print(prompt)\n",
    "  response = client.chat.completions.create(\n",
    "    messages=[{\n",
    "          \"role\": \"user\",\n",
    "          \"content\": prompt,\n",
    "        }],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    )\n",
    "  result = response.choices[0].message.content\n",
    "  return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devtest folder will be used for this baseline testing as dev\n",
    "# may be more likely to appear in training data\n",
    "flores_dataset = \"../flores/floresp-v2.0-rc.2/devtest\"\n",
    "\n",
    "language_datasets = os.listdir(flores_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Source & Target Languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def select_random_language_from_dataset():\n",
    "\n",
    "\n",
    "    # Randomly select source and target languages\n",
    "    src_language_dataset = random.choice(language_datasets)\n",
    "    targ_language_dataset = random.choice(language_datasets)\n",
    "\n",
    "    # Assure that the source and target languages are not the same\n",
    "    while targ_language_dataset == src_language_dataset:\n",
    "        targ_language_dataset = random.choice(language_datasets)\n",
    "\n",
    "    # Pull a random line from source and target datasets\n",
    "\n",
    "    src_sentences = []\n",
    "    targ_sentences = []\n",
    "\n",
    "    def read_dataset(path):\n",
    "        with open(flores_dataset + \"/\" + path, 'r', encoding=\"utf-8\") as dataset_file:\n",
    "            lines = dataset_file.readlines()\n",
    "            total_lines = len(lines)\n",
    "        return lines, total_lines\n",
    "\n",
    "            \n",
    "    src_lines, total_lines = read_dataset(src_language_dataset)\n",
    "    targ_lines, total_lines = read_dataset(targ_language_dataset)\n",
    "\n",
    "    selected_line_int = random.randint(1, total_lines)\n",
    "\n",
    "\n",
    "    selected_line_src = src_lines[selected_line_int - 1]\n",
    "    selected_line_targ = targ_lines[selected_line_int - 1]\n",
    "\n",
    "    return selected_line_src, selected_line_targ, src_language_dataset, targ_language_dataset\n",
    "\n",
    "    # print(selected_line_int)\n",
    "    # print(selected_line_src)\n",
    "\n",
    "    # print(src_sentences)\n",
    "    # print(targ_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate source to target using our POC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate source to target using stock GPT 3.5 Turbo\n",
    "\n",
    "def translate_gpt_api(selected_line_src, src_language_dataset, targ_language_dataset):\n",
    "    prompt = f'Translate \"{selected_line_src}\" from the {src_language_dataset} language into the target language {targ_language_dataset}. Output only the translated sentence'\n",
    "    translation = \"\"\n",
    "\n",
    "    client = OpenAI(api_key= OPENAI_API_KEY,)\n",
    "    print(prompt)\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "            }],\n",
    "        model=\"gpt-3.5-turbo\",)\n",
    "        # model=\"gpt-4o\",)\n",
    "\n",
    "    hypothesized_translation = response.choices[0].message.content.strip().split(\"\\n\")[0]\n",
    "\n",
    "    # print(\"\\n\\nMANUAL CHECK LIST PARAMS\\n\\n\")\n",
    "\n",
    "    # print(src_language_dataset, src_sentences)\n",
    "    # print(targ_language_dataset, targ_sentences)\n",
    "\n",
    "\n",
    "    # print(f'TRANSLATION: {hypothesized_translation}')\n",
    "\n",
    "    return hypothesized_translation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute spBLEU & chrF++ Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are reference cells using the scores with english language sentence showing how it works. \n",
    "\n",
    "```hypothesized_translation``` can be just a string which contains the translation from our model\n",
    "\n",
    "```target_translation``` should be a list of strings (the score expects list of lists of strings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All sentences being fed to the score, ```hypothesized_translation``` and all strings in ```target_translation``` are all in the same language. Be careful with what each variable contains there are similar named variables in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(hypothesized_translation, targ_selected_line, target_translation):\n",
    "    \n",
    "    print('\\n\\n')\n",
    "    \n",
    "    bleu_score  = sacrebleu.corpus_bleu([hypothesized_translation], [target_translation], tokenize=\"intl\")\n",
    "    print(\"spBLEU Score: \", bleu_score.score)\n",
    "\n",
    "    chr_score  = sacrebleu.corpus_chrf([hypothesized_translation], [target_translation])\n",
    "\n",
    "    print(\"chrF++ Score: \", chr_score.score)\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    print(\"Hypothesized Translation: \", hypothesized_translation)\n",
    "    print(\"Target Translation: \", targ_selected_line)\n",
    "\n",
    "    # return bleu_score, chr_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT 3.5 Turbo Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate \"Ko tshimologong, lenaneo leno le ne le gasiwa fela mo tsebeng ya nthanete ya  seromanowa sa Toginet, tsebe e e ikemeseditseng go gasa puisano ya diromamowa.\n",
      "\" from the devtest.tsn_Latn language into the target language devtest.spa_Latn. Output only the translated sentence\n",
      "\n",
      "\n",
      "\n",
      "spBLEU Score:  3.4784906414591865\n",
      "chrF++ Score:  28.406866326347696\n",
      "\n",
      "\n",
      "Hypothesized Translation:  Cuando Tshimologong, este espacio solo está reservado para el programa de fin de semana de Toginet, donde se concentra en la mezcla de música.\n",
      "Target Translation:  En sus inicios, el programa se emitía solo en el sitio de radio por internet, TogiNet Radio, un espacio de larga data enfocado en el formato de radio hablada.\n",
      "\n",
      "En sus inicios, el programa se emitía solo en el sitio de radio por internet, TogiNet Radio, un espacio de larga data enfocado en el formato de radio hablada.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "src_selected_line, targ_selected_line, src_language_dataset, targ_language_dataset = select_random_language_from_dataset()\n",
    "\n",
    "\n",
    "hypothesized_translation = translate_gpt_api(src_selected_line, src_language_dataset, targ_language_dataset)\n",
    "target_translation = [targ_selected_line]\n",
    "\n",
    "get_scores(hypothesized_translation, targ_selected_line, target_translation)\n",
    "print(targ_selected_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our POC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_selected_line, targ_selected_line, src_language_dataset, targ_language_dataset = select_random_language_from_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate the following text from mar_Deva into cym_Latn: आपण केवळ शिपबोर्ड सहल वापरुन किनारपट्टीवर जात असल्यास आपल्याला वेगळ्या व्हिजाची (2009 पर्यंत) आवश्यकता नाही.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "spBLEU Score:  6.354504873535819\n",
      "chrF++ Score:  25.087676048724433\n",
      "\n",
      "\n",
      "Hypothesized Translation:  Os nad ydi dim ond ar y long ar gyfer neidio i'r arfordir, nid oes angen ffagiau gwahanol arnoch hyd at 2009.\n",
      "Target Translation:  Os byddwch chi ond yn mynd i'r lan gan ddefnyddio gwibdeithiau bwrdd llong ni fydd angen fisa ar wahân arnoch chi (yn 2009).\n",
      "\n"
     ]
    }
   ],
   "source": [
    "poc_prompt = prompt_generator(src_selected_line, src_language_dataset, targ_language_dataset)\n",
    "\n",
    "poc_hypothesized_translation = translate_text(poc_prompt)\n",
    "\n",
    "\n",
    "# Scores\n",
    "target_translation = [targ_selected_line]\n",
    "\n",
    "get_scores(poc_hypothesized_translation, targ_selected_line, target_translation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate \"Molao wa Fora ba dikgetho o hlakisa ka tiyo tshebetso ena.\n",
      "\" from the devtest.sot_Latn language into the target language devtest.smo_Latn. Output only the translated sentence\n",
      "\n",
      "\n",
      "\n",
      "spBLEU Score:  4.724932626401583\n",
      "chrF++ Score:  17.85745914348874\n",
      "\n",
      "\n",
      "Hypothesized Translation:  O le Molao o lo'o fa'amalie i le faia o ni ti'o lava i lelei.\n",
      "Target Translation:  O le tulafono o palota fa’a-Farani e fa’amalosia ai le vaevaeina o taualumaga.\n",
      "\n",
      "O le tulafono o palota fa’a-Farani e fa’amalosia ai le vaevaeina o taualumaga.\n",
      "\n",
      "Translate the following text from sot_Latn into smo_Latn: Molao wa Fora ba dikgetho o hlakisa ka tiyo tshebetso ena.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "spBLEU Score:  2.2796871594840864\n",
      "chrF++ Score:  11.883268435023803\n",
      "\n",
      "\n",
      "Hypothesized Translation:  The work of Fora is not a mere decision but rather an enhancement of this service.\n",
      "Target Translation:  O le tulafono o palota fa’a-Farani e fa’amalosia ai le vaevaeina o taualumaga.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "src_selected_line, targ_selected_line, src_language_dataset, targ_language_dataset = select_random_language_from_dataset()\n",
    "\n",
    "\n",
    "hypothesized_translation = translate_gpt_api(src_selected_line, src_language_dataset, targ_language_dataset)\n",
    "target_translation = [targ_selected_line]\n",
    "\n",
    "get_scores(hypothesized_translation, targ_selected_line, target_translation)\n",
    "print(targ_selected_line)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "poc_prompt = prompt_generator(src_selected_line, src_language_dataset, targ_language_dataset)\n",
    "\n",
    "poc_hypothesized_translation = translate_text(poc_prompt)\n",
    "\n",
    "\n",
    "# Scores\n",
    "target_translation = [targ_selected_line]\n",
    "\n",
    "get_scores(poc_hypothesized_translation, targ_selected_line, target_translation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
