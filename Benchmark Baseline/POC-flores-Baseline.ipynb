{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial Config\n",
    "\n",
    "\n",
    "Note from Mekael\n",
    "- For my team, use a virutal environment to keep deployment operations clean and tidy\n",
    "- You can do this by running the following command in your terminal\n",
    "- `python -m venv error-in-translations`\n",
    "- Activate the environment by selecting it as your kernel for your jupyter notebook. If it doesn't work you will have to figure it out\n",
    "- pip install the packages in the requirements file in the root directory of this repo\n",
    "- `pip install -r requirements.txt`\n",
    "\n",
    "\n",
    "- **If you install new packages that are not included in the environment, please add it to the requirements file manually or generate a new requirements file with the following command in the terminal**\n",
    "- `pip freeze > requirements.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/openlanguagedata/flores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import os\n",
    "import spacy\n",
    "import random\n",
    "import sacrebleu\n",
    "\n",
    "# Not working\n",
    "OPENAI_API_KEY = 'sk-proj-o9TONJi0MW2tSiDMhRkxT3BlbkFJkUr03XQ5IfUaxamV0e3k'\n",
    "\n",
    "# Mekael's Personal Key, not being shared\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Benchmark\n",
    "\n",
    "This benchmark sets a baseline and tests the translation precision & accuracy our POC pipeline, against the bare translation capabilities of OPENAI's CHATGPT 3.5 Turbo via their API.\n",
    "\n",
    "If our POC performs better than the stock GPT 3.5 Turbo, it means that our proposed method is valubale and worthwhile to implement. \n",
    "\n",
    "For baseline testing purposes, our POC makes use of custom GPT 3.5 API prompting as the translation model as well as the quality estimation model. These will be replaced with a more sophisticated custom LLM solution during actual implementation.\n",
    "\n",
    "We will be using Meta's Flores 200 dataset for this testing, and scores will be in the form of spBLEU and/or chrF++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text Lines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>On Monday, scientists from the Stanford Univer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lead researchers say this may bring early dete...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The JAS 39C Gripen crashed onto a runway at ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The pilot was identified as Squadron Leader Di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Local media reports an airport fire vehicle ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>984</th>\n",
       "      <td>The tourist season for the hill stations gener...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>985</th>\n",
       "      <td>However, they have a different kind of beauty ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>Only a few airlines still offer bereavement fa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>987</th>\n",
       "      <td>Airlines that offer these include Air Canada, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>988</th>\n",
       "      <td>In all cases, you must book by phone directly ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>989 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Text Lines\n",
       "0    On Monday, scientists from the Stanford Univer...\n",
       "1    Lead researchers say this may bring early dete...\n",
       "2    The JAS 39C Gripen crashed onto a runway at ar...\n",
       "3    The pilot was identified as Squadron Leader Di...\n",
       "4    Local media reports an airport fire vehicle ro...\n",
       "..                                                 ...\n",
       "984  The tourist season for the hill stations gener...\n",
       "985  However, they have a different kind of beauty ...\n",
       "986  Only a few airlines still offer bereavement fa...\n",
       "987  Airlines that offer these include Air Canada, ...\n",
       "988  In all cases, you must book by phone directly ...\n",
       "\n",
       "[989 rows x 1 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_dataset = \"../flores/floresp-v2.0-rc.2/dev/dev.eng_Latn\"\n",
    "\n",
    "# Rename the Column\n",
    "column_names = [\"Text Lines\"]\n",
    "\n",
    "# Read in the Flores Dataset English Latn\n",
    "df = pd.read_csv(english_dataset, delimiter = '\\t', header=None, names=column_names)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select Source & Target Languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Devtest folder will be used for this baseline testing as dev\n",
    "# may be more likely to appear in training data\n",
    "flores_dataset = \"../flores/floresp-v2.0-rc.2/devtest\"\n",
    "\n",
    "language_datasets = os.listdir(flores_dataset)\n",
    "\n",
    "\n",
    "# Randomly select source and target languages\n",
    "src_language_dataset = random.choice(language_datasets)\n",
    "targ_language_dataset = random.choice(language_datasets)\n",
    "\n",
    "# Assure that the source and target languages are not the same\n",
    "while targ_language_dataset == src_language_dataset:\n",
    "    targ_language_dataset = random.choice(language_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translations using our proposed method (POC) and stock GPT 3.5 Turbo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add POC (no glossary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt with entity translation\n",
    "def prompt_generator(text, source_language, target_language):\n",
    "  prompt = f\"Translate the following text from {source_language} into {target_language}: {text}\\n\"\n",
    "  if terms == {}:\n",
    "    return prompt\n",
    "  prompt = translations + prompt\n",
    "\n",
    "  return prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Translation code, can be replaced by other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_text(prompt):\n",
    "\n",
    "    client = OpenAI(api_key= OPENAI_API_KEY,)\n",
    "    print(prompt)\n",
    "    response = client.chat.completions.create(\n",
    "      messages=[{\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "          }],\n",
    "      model=\"gpt-3.5-turbo\",)\n",
    "    translation = response.choices[0].message.content.strip().split(\"\\n\")[0]\n",
    "    return translation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quality Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_estimator(original_text, translated_text):\n",
    "  client = OpenAI(api_key= OPENAI_API_KEY,)\n",
    "  prompt = f\"Evaluate the quality estimation of the following source and translation sentence pairs by following a step-by-step process: \\\n",
    "    Step 1: Estimate the perplexity of the translated sentence.\\\n",
    "    Step 2: Determine the token-level similarity between the source and translatedsentences.\\\n",
    "    Step 3: Combine the results and classify the translation quality into one of the following categories:'No meaning preserved', 'Some meaning preserved, but not understandable', 'Some meaning preserved and understandable', 'Most meaningpreserved, minor issues',or 'Perfect translation'.\\\n",
    "    Source:{original_text}.Translation:{translated_text}\"\n",
    "  print(prompt)\n",
    "  response = client.chat.completions.create(\n",
    "    messages=[{\n",
    "          \"role\": \"user\",\n",
    "          \"content\": prompt,\n",
    "        }],\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    )\n",
    "  result = response.choices[0].message.content\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quality_classifier(evaluation):\n",
    "  start_index = evaluation.find(\"'\")\n",
    "  end_index = evaluation.find(\"'\", start_index + 1)\n",
    "  category = evaluation[start_index+1:end_index]\n",
    "  return category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate the quality estimation of the following source and translation sentence pairs by following a step-by-step process:     Step 1: Estimate the perplexity of the translated sentence.    Step 2: Determine the token-level similarity between the source and translatedsentences.    Step 3: Combine the results and classify the translation quality into one of the following categories:'No meaning preserved', 'Some meaning preserved, but not understandable', 'Some meaning preserved and understandable', 'Most meaningpreserved, minor issues',or 'Perfect translation'.    Source:光纤照上去变成黑光纤了.Translation:The fiber optic cable shines and turns into dark fiber.\n",
      "Step 1: Estimate the perplexity of the translated sentence.\n",
      "\n",
      "Perplexity is a measure of how well a probability model predicts a sample. In the context of machine translation, a lower perplexity score indicates better translation quality. We would need a language model to calculate the perplexity score accurately, but we can estimate it by considering the fluency and coherence of the translated sentence. \n",
      "\n",
      "Step 2: Determine the token-level similarity between the source and translated sentences.\n",
      "\n",
      "Source: 光纤 照 上去 变 成 黑 光纤 了\n",
      "Translation: The fiber optic cable shines and turns into dark fiber\n",
      "\n",
      "Token-level similarity: \n",
      "- 光纤 (fiber optic cable) -> The fiber optic cable\n",
      "- 照上去 (shines and turns into) -> shines and turns into\n",
      "- 变成 (becomes) -> turns into\n",
      "- 黑 (dark) -> dark\n",
      "- 光纤 (fiber) -> fiber\n",
      "\n",
      "Step 3: Combine the results and classify the translation quality into one of the following categories:\n",
      "\n",
      "The translation \"The fiber optic cable shines and turns into dark fiber\" shows some meaning preserved, but not completely accurate or understandable. The translation includes some correct terms like \"fiber optic cable\" and \"dark,\" but the phrase \"shines and turns into\" does not accurately convey the original meaning.\n",
      "\n",
      "Therefore, based on the analysis, this translation can be classified as 'Some meaning preserved, but not understandable'.\n"
     ]
    }
   ],
   "source": [
    "original_text = \"光纤照上去变成黑光纤了\"\n",
    "translated_text = \"The fiber optic cable shines and turns into dark fiber.\"\n",
    "evaluation = quality_estimator(original_text, translated_text)\n",
    "print(evaluation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "849\n",
      "Wɔn a wɔforo abotan a wofi wiase afanan nyinaa no gu so renya akwan foforo ahorow wɔ afasu bebree a wobetumi aforo no ho,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pull a random line from source and target datasets\n",
    "\n",
    "src_sentences = []\n",
    "targ_sentences = []\n",
    "\n",
    "def read_dataset(path):\n",
    "    with open(flores_dataset + \"/\" + path, 'r', encoding=\"utf-8\") as dataset_file:\n",
    "        lines = dataset_file.readlines()\n",
    "        total_lines = len(lines)\n",
    "    return lines, total_lines\n",
    "\n",
    "        \n",
    "src_lines, total_lines = read_dataset(src_language_dataset)\n",
    "targ_lines, total_lines = read_dataset(src_language_dataset)\n",
    "\n",
    "selected_line_int = random.randint(1, total_lines)\n",
    "\n",
    "print(selected_line_int)\n",
    "\n",
    "selected_line_src = src_lines[selected_line_int - 1]\n",
    "selected_line_targ = targ_lines[selected_line_int - 1]\n",
    "\n",
    "print(selected_line_src)\n",
    "# print(src_sentences)\n",
    "# print(targ_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "devtest.twi_Latn_akua1239\n"
     ]
    }
   ],
   "source": [
    "print(src_language_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Translate source to target using our POC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate \"Wɔn a wɔforo abotan a wofi wiase afanan nyinaa no gu so renya akwan foforo ahorow wɔ afasu bebree a wobetumi aforo no ho,\n",
      "\" from the devtest.twi_Latn_akua1239 language into the target language devtest.kab_Latn\n",
      "\n",
      "\n",
      "MANUAL CHECK LIST PARAMS\n",
      "\n",
      "\n",
      "devtest.twi_Latn_akua1239 []\n",
      "devtest.kab_Latn []\n",
      "TRANSLATION: \"Wɔn a wɔforo abotan a wofi wiase afanan nyinaa no gu so renya akwan foforo ahorow wɔ afasu bebree a wobetumi aforo no ho,\" translates to \"Tzɂa i nchbraben a ɚen anchkaandan tsʋbo sha jirjelkoo atusre inyeme ahalɩbli i tsʋkpa dunzakɔkpir abrabrɩtɔ\" in Kab_Latn.\n"
     ]
    }
   ],
   "source": [
    "# Translate source to target using stock GPT 3.5 Turbo\n",
    "\n",
    "prompt = f'Translate \"{selected_line_src}\" from the {src_language_dataset} language into the target language {targ_language_dataset}'\n",
    "translation = \"\"\n",
    "\n",
    "client = OpenAI(api_key= OPENAI_API_KEY,)\n",
    "print(prompt)\n",
    "response = client.chat.completions.create(\n",
    "    messages=[{\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt,\n",
    "        }],\n",
    "    model=\"gpt-3.5-turbo\",)\n",
    "\n",
    "hypothesized_translation = response.choices[0].message.content.strip().split(\"\\n\")[0]\n",
    "\n",
    "print(\"\\n\\nMANUAL CHECK LIST PARAMS\\n\\n\")\n",
    "\n",
    "print(src_language_dataset, src_sentences)\n",
    "print(targ_language_dataset, targ_sentences)\n",
    "\n",
    "\n",
    "print(f'TRANSLATION: {hypothesized_translation}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute spBLEU & chrF++ Scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are reference cells using the scores with english language sentence showing how it works. \n",
    "\n",
    "```hypothesized_translation``` can be just a string which contains the translation from our model\n",
    "\n",
    "```target_translation``` should be a list of strings (the score expects list of lists of strings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spBLEU Score:  1.2414943415352928\n"
     ]
    }
   ],
   "source": [
    "target_translation = targ_sentences\n",
    "\n",
    "bleu_score  = sacrebleu.corpus_bleu([hypothesized_translation], [target_translation], tokenize=\"intl\")\n",
    "print(\"spBLEU Score: \", bleu_score.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chrF++ Score:  86.51314090979501\n"
     ]
    }
   ],
   "source": [
    "hypothesized_translation = \"Lose track of ti\"\n",
    "target_translation = \"Lose track of time\"\n",
    "\n",
    "bleu_score  = sacrebleu.corpus_chrf([hypothesized_translation], [[target_translation]])\n",
    "print(\"chrF++ Score: \", bleu_score.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a demo trying to find out why the score is so bad. If you want to approach then change the stuff below. NOTE: ```target_translation``` should be a list of lists of strings that are in the TARGET LANGUAGE as REFERENCES for the score to judge against. This means that all sentences being fed to the score, ```hypothesized_translation``` and all strings in ```target_translation``` are all in the same language. Be careful with what each variable contains there are similar named variables in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spBLEU Score:  46.493318002787895\n",
      "chrF++ Score:  79.9140429774981\n",
      "\"Wɔn a wɔforo abotan a wofi wiase afanan nyinaa no gu so renya akwan foforo ahorow wɔ afasu bebree a wobetumi aforo no ho,\" translates to \"Tzɂa i nchbraben a ɚen anchkaandan tsʋbo sha jirjelkoo atusre inyeme ahalɩbli i tsʋkpa dunzakɔkpir abrabrɩtɔ\" in Kab_Latn.\n",
      "Wɔn a wɔforo abotan a wofi wiase afanan nyinaa no gu so renya akwan foforo ahorow wɔ afasu bebree a wobetumi aforo no ho,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# hypothesized_translation = \"Anḍil aṭas uṭṭun d ayen n 'feral' neɣ uṭṭun. Imdukkal yessnen ayen yal aṭṭun wagi ɣef wulawen-is (asnin-iten yakan weḥḍen); yella d aṭṭun yessufeɣ aḥric neɣ yelha d acu kan aɣewṭur\"\n",
    "\n",
    "\n",
    "hypothesized_translation = hypothesized_translation\n",
    "\n",
    "\n",
    "target_translation = [selected_line_targ\n",
    "]\n",
    "\n",
    "bleu_score  = sacrebleu.corpus_bleu([hypothesized_translation], [target_translation], tokenize=\"intl\")\n",
    "print(\"spBLEU Score: \", bleu_score.score)\n",
    "\n",
    "chr_score  = sacrebleu.corpus_chrf([hypothesized_translation], [target_translation])\n",
    "print(\"chrF++ Score: \", chr_score.score)\n",
    "\n",
    "print(hypothesized_translation)\n",
    "# print(selected_line_src)\n",
    "print(selected_line_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spBLEU Score:  100.00000000000004\n",
      "chrF++ Score:  100.0\n"
     ]
    }
   ],
   "source": [
    "import sacrebleu\n",
    "\n",
    "hypothesized_translation = [\"Je perds la notion du temps, je deviens fou.\"]\n",
    "target_translation = [[\"Je perds la notion du temps, je deviens fou.\"]]\n",
    "\n",
    "bleu_score  = sacrebleu.corpus_bleu(hypothesized_translation, target_translation, tokenize=\"intl\")\n",
    "print(\"spBLEU Score: \", bleu_score.score)\n",
    "\n",
    "chr_score  = sacrebleu.corpus_chrf(hypothesized_translation, target_translation)\n",
    "print(\"chrF++ Score: \", chr_score.score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spBLEU Score:  1.1734190039234365\n"
     ]
    }
   ],
   "source": [
    "# hypothesized_translation = \"Anḍil aṭas uṭṭun d ayen n 'feral' neɣ uṭṭun. Imdukkal yessnen ayen yal aṭṭun wagi ɣef wulawen-is (asnin-iten yakan weḥḍen); yella d aṭṭun yessufeɣ aḥric neɣ yelha d acu kan aɣewṭur\"\n",
    "\n",
    "\n",
    "hypothesized_translation = \"Tsere tsin abu bay ɣud jabeg ma, ɣur nu wira. Tɛɣa tu tɔb tɛna, tu aɣa d bul bay tɛt bayu. Nyenta but gan, nynta n ma jkung ta ndejɣa nuut bay ta.\"\n",
    "\n",
    "\n",
    "target_translation = ['ɣer taggara n Tallit Talemmast Tuṛuft n umalu tebda ad tesnulfuy aɣan n yiman-is. yiwen n usnulfu meqqren akk n tallit d ayen i yeǧǧan imdanen n yimidagen ad bdun ad ttarran tiqeffilin i wakken ad ṭṭfen iceṭṭiḍen-nsen.',\n",
    "'Tafellaḥt n tudert d tafellaḥt i xeddmen i ufares n ddeqs n wučči i wakken kan ad ččen ifellaḥen d twaculin-nsen.',\n",
    "'Tafellaḥt n tudert d anagraw isehlen, tikkwal agaman, s usexdem n zzeriεa n tmurt-nni yettwajemεen i sdukkulen s tuzzya n yirden neɣ timamkin tiḥerfiyin icudden ɣer waya i wakken ad snernin lɣella.',\n",
    "'Deg umezruy tuget n yifellaḥen ttekkan deg tfellaḥt n tudert yerna d ayen mazal ɣer tura deg waṭas n yiɣlanen deg ubrid n tneflit.',\n",
    "'Idelsan imecṭaḥ jemεen-d imdanen yesεan tidmiyin yettemcabin yettḥassan d akken ttwaεzalen seg yilugan imettiyen yerna fkan-asen tagnit i wakken sneflin anamek n tmagit.',\n",
    "'Nezmer ad d-neεqel idelsan imecṭaḥ s leεmeṛ, agraw atni, taserkemt, adeg, d/neɣ tuzzuft n yimaṣlaḍen.',\n",
    "'Tulmisin yesbanayen amek ad tεeqleḍ adles amecṭuḥ zemrent ad ilint d tisnilsanin, tifulkanin, tisɣanin, tisertiyin, tuzzufin, tirakalin, neɣ d asdukkel n yimgan.',\n",
    "'Imaṣlaḍen n udles amecṭuḥ zgan sbanayen-d attekki-nsen s usexdem azamulan n waɣan yettmaεqalen , am lebsa, tikli, d tmeslayt.',\n",
    "'Yiwet si tarrayin timagnutin akk yettwasxedmen i wakken ad d-nesmedya azal n usmetti d tumla n kra n tejṛutin yettuɣaḍen n warrac imecṭaḥ i, s ustehzi, lexṣaṣ n zher, neɣ tameḥqranit s lebɣi, ur ten-smettin ara imengaḍen mi ttimɣuren.',\n",
    "'Arrac imecṭaḥ am wigi qqaren-asen d \"imulasen\" neɣ d iweḥciyen. Kra n warrac imecṭaḥ imulasen qqnen-ten deg uxxam yemdanen (s wudem imezgi d imawlan-nsen); di kra n tejṛutin n usinef n ugrud-agi yella-d imi imawlan ur qbilen ara iɣeblan n tdawsa taɣaṛant d taggagt iweεren n ugrud. ',\n",
    "'Igerdan iweḥciyen yezmer jerrben tamuḥqranit neɣ d tiyita qessiḥen uqbel ad ten-ǧǧen neɣ ad rewlen.',\n",
    "'Llan wiyaḍ qqaren-d fell-asen d akken rebban-ten-id iɣersiwen; kra niḍen nnan-d fell-asen d akken dren deg teẓgi i yiman-nsen.',\n",
    "'Imi tturebban-d s wudem ummid sɣur iɣersiwen war-alsiyen, igerdan iweḥciyen ttammalen-d tikli ( s tilisa tiɣaṛanin) qrib am tin n yiɣersiwen i ten-irebban, am tugdi-nsen neɣ tigurzent ɣer yilsiyen.',\n",
    "'Imi almad yebnan ɣef usenfar yessishil almad yerna yettara-t yesεa azal, tasuki n leεḍil tεedda akkin i waya.',\n",
    "'Tasuki n leεḍil ur telli d tarrayt n ulmad maca d lemεawna i yettεawanen imdanen i yesεan tirmit n ulmad tamaynut am usexdem n useɣzan amaynut n uselkam neɣ tazwara n usenfar amaynut.',\n",
    "'Wid-agi yettεawanen zemren ad ilin d uhlisen neɣ d ilawen, s wawalen niḍen, aselmad d talɣa n umεiwen maca ula d amessak n lkaɣeḍ n Lbiru Mikrusuft.',\n",
    "'Imεiwnen uhlisen llan deg useɣzan yerna llan i wakken ad steqsin, sḥercen, akked ad segzun tisekkirin iweεṛen i yinelmaden ad tent-fehmen s yiman-nsen.',\n",
    "'Igerdan ttilin deg Ixxamen n Twaculin niḍen ɣef waṭas n ssebbat tanḍiyin seg ustehzi, tamuḥqranit, ula ɣer tukksa.',\n",
    "'Ur yelli ugrud ilaqen ad yimɣur deg uxxam anda ulac leḥmala, aseḥbiber, d usinen, maca nutni ddren akka.',\n",
    "'Nettwali d akken Anagraw n Twaculin Yettrebbin d adeg yesεan taɣellist i yigerdan-agi.',\n",
    "'Anagraw-nneɣ n twaculin yettrebbin tiṭ-is ad yefk ixxamen yesεan taɣellist, imejjayen yesεan tayri, asinen irekden, d asejji bu taflest.',\n",
    "'Ixxamen n twaculin yettrebbin ilaq ad sεun akk ayen ixuṣṣen deg yixxamen seg ansi id ten-id-yekksen yakan.',\n",
    "'Internet yesdukkel iferdisen n teɣwalt n waṭas n lɣaci d tin gar yemdanen.',\n",
    "'Tulmisin tufṛizin n Internet ṣṣawaḍent ɣer tsektiwin timernanin deg wayen yeεnan tudsa n useqdec akked taḍfi.',\n",
    "'D amedya, \"almad\" d \"wesmetti\" summren-ten am isguffden ixataren i useqdec n Internet (James d wiyaḍ., 1995).',\n",
    "]\n",
    "\n",
    "bleu_score  = sacrebleu.corpus_bleu([hypothesized_translation], [target_translation], tokenize=\"intl\")\n",
    "print(\"spBLEU Score: \", bleu_score.score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "chrF++ Score:  18.932100676864668\n"
     ]
    }
   ],
   "source": [
    "hypothesized_translation = \"Anḍil aṭas uṭṭun d ayen n 'feral' neɣ uṭṭun. Imdukkal yessnen ayen yal aṭṭun wagi ɣef wulawen-is (asnin-iten yakan weḥḍen); yella d aṭṭun yessufeɣ aḥric neɣ yelha d acu kan aɣewṭur\"\n",
    "target_translation = ['ɣer taggara n Tallit Talemmast Tuṛuft n umalu tebda ad tesnulfuy aɣan n yiman-is. yiwen n usnulfu meqqren akk n tallit d ayen i yeǧǧan imdanen n yimidagen ad bdun ad ttarran tiqeffilin i wakken ad ṭṭfen iceṭṭiḍen-nsen.',\n",
    "'Tafellaḥt n tudert d tafellaḥt i xeddmen i ufares n ddeqs n wučči i wakken kan ad ččen ifellaḥen d twaculin-nsen.',\n",
    "'Tafellaḥt n tudert d anagraw isehlen, tikkwal agaman, s usexdem n zzeriεa n tmurt-nni yettwajemεen i sdukkulen s tuzzya n yirden neɣ timamkin tiḥerfiyin icudden ɣer waya i wakken ad snernin lɣella.',\n",
    "'Deg umezruy tuget n yifellaḥen ttekkan deg tfellaḥt n tudert yerna d ayen mazal ɣer tura deg waṭas n yiɣlanen deg ubrid n tneflit.',\n",
    "'Idelsan imecṭaḥ jemεen-d imdanen yesεan tidmiyin yettemcabin yettḥassan d akken ttwaεzalen seg yilugan imettiyen yerna fkan-asen tagnit i wakken sneflin anamek n tmagit.',\n",
    "'Nezmer ad d-neεqel idelsan imecṭaḥ s leεmeṛ, agraw atni, taserkemt, adeg, d/neɣ tuzzuft n yimaṣlaḍen.',\n",
    "'Tulmisin tufṛizin n Internet ṣṣawaḍent ɣer tsektiwin timernanin deg wayen yeεnan tudsa n useqdec akked taḍfi.',\n",
    "'D amedya, \"almad\" d \"wesmetti\" summren-ten am isguffden ixataren i useqdec n Internet (James d wiyaḍ., 1995).',\n",
    "]\n",
    "\n",
    "chr_score  = sacrebleu.corpus_chrf([hypothesized_translation], [target_translation])\n",
    "print(\"chrF++ Score: \", chr_score.score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dummy cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU Score: 86.27788640890412\n"
     ]
    }
   ],
   "source": [
    "# Hypotheses (system translations)\n",
    "hypotheses = [\"This is a test translation.\", \"Here is another sentence.\"]\n",
    "\n",
    "# References (each sublist contains the reference translations for one hypothesis)\n",
    "references = [\n",
    "    [\"This is a test translation.\", \"This is a trial translation.\"],\n",
    "    [\"Here is another sentence.\", \"This is another sentence.\"]\n",
    "]\n",
    "\n",
    "# Compute the BLEU score using a specific tokenizer ('intl' or '13a', 'zh' for Chinese, etc.)\n",
    "bleu_score = sacrebleu.corpus_bleu(hypotheses, references, tokenize='intl')\n",
    "print(\"BLEU Score:\", bleu_score.score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
